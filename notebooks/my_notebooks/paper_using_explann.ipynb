{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Planning Applied to Energetic Process - ENE108\n",
    "\n",
    "Dr. Fernando Gasi; Dra. Graziella Colato Antonio; Dra. Juliana TÃ³fano de Campos Leite Toneli\n",
    "\n",
    "\n",
    "# Article Selected\n",
    "\n",
    "\n",
    "The economical feasibility of ethanol production using lignocellulosic biomass is primarilly dependent on the cost of the required enzymes, e.g. celullase. By this reason there is and increasing interest in optimizing the process of obtaining this enzymes. In the article [Nitrogen Source Optimization for Cellulase Production\n",
    "by Penicillium funiculosum, using a Sequential\n",
    "Experimental Design Methodology and the Desirability\n",
    "Function](https://link.springer.com/content/pdf/10.1007/s12010-009-8875-6.pdf?pdf=button), the authors used three sucessice designs of experiments to optimize celullase production. The incremental methodology consists of sucessively cut off irrelevant terms in models obtained by a $2^4$ and $2^3$ factorial designs and finally perform ANOVA in a central composite rotational design. \n",
    "\n",
    "# Variables and Levels\n",
    "\n",
    "# Responses\n",
    "\n",
    "# Matrices of experiments\n",
    "\n",
    "# ANOVA\n",
    "\n",
    "# Hypotesis\n",
    "\n",
    "The main hypotesis is that a sequential methodology for experimental design can be efficiently used to optmizethe the production of celullase by *Penicillinum funiculosum*. \n",
    "\n",
    "# Cellulalse Production Process\n",
    "\n",
    "For optimization of cellulase production, the independent variables considered were 4 different sources of nitrogen:\n",
    "\n",
    "- Urea (`Urea`)\n",
    "- Ammonium Sulfate (`AmmoniumSulfate`)\n",
    "- Peptone (`Peptone`)\n",
    "- Yeast Extract (`YeastExtract`)\n",
    "\n",
    "# $2^4$ Factorial Experiment\n",
    "\n",
    "for the first experiment all independent variables was considered on a factorial design with two levels and three central points as described in the table below"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Urea | AmmoniumSulfate | Peptone | YeastExtract | FPase | CMCase | BetaGlucosidase |\n",
    "|-----:|----------------:|--------:|-------------:|------:|-------:|-----------------|\n",
    "|   -1 |              -1 |      -1 |           -1 |    39 |  1.328 | 170             |\n",
    "|    1 |              -1 |      -1 |           -1 |    87 |  1.699 | 122             |\n",
    "|   -1 |               1 |      -1 |           -1 |    48 |  1.332 | 473             |\n",
    "|    1 |               1 |      -1 |           -1 |    71 |  1.979 | 511             |\n",
    "|   -1 |              -1 |       1 |           -1 |    43 |  1.458 | 156             |\n",
    "|    1 |              -1 |       1 |           -1 |    84 |  2.189 | 204             |\n",
    "|   -1 |               1 |       1 |           -1 |    45 |  1.343 | 385             |\n",
    "|    1 |               1 |       1 |           -1 |   112 |  1.707 | 288             |\n",
    "|   -1 |              -1 |      -1 |            1 |    19 |  1.257 | 114             |\n",
    "|    1 |              -1 |      -1 |            1 |   146 |  2.148 | 116             |\n",
    "|   -1 |               1 |      -1 |            1 |    50 |  1.592 | 244             |\n",
    "|    1 |               1 |      -1 |            1 |    92 |  1.726 | 126             |\n",
    "|   -1 |              -1 |       1 |            1 |   107 |  1.203 | 72              |\n",
    "|    1 |              -1 |       1 |            1 |   172 |  2.261 | 210             |\n",
    "|   -1 |               1 |       1 |            1 |    62 |  1.434 | 234             |\n",
    "|    1 |               1 |       1 |            1 |    82 |  1.848 | 154             |\n",
    "|    0 |               0 |       0 |            0 |    75 |  1.726 | 223             |\n",
    "|    0 |               0 |       0 |            0 |    70 |  1.782 | 219             |\n",
    "|    0 |               0 |       0 |            0 |    89 |  1.753 | 226             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ImportData' from 'explann.dataio' (/home/ppiper/Dropbox/local/github/explann/explann/dataio/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m\n\u001b[1;32m      2\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m/home/ppiper/Dropbox/local/github/explann\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mexplann\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdataio\u001b[39;00m \u001b[39mimport\u001b[39;00m ImportData\n\u001b[1;32m      6\u001b[0m table_24 \u001b[39m=\u001b[39m ImportData(\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[39mU;A;P;Y;F;C;B\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[39m-1;-1;-1;-1;39;1.328;170\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39m0;0;0;0;89;1.753;226\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[39m\"\"\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ImportData' from 'explann.dataio' (/home/ppiper/Dropbox/local/github/explann/explann/dataio/__init__.py)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ppiper/Dropbox/local/github/explann')\n",
    "\n",
    "from explann.dataio import ImportData\n",
    "\n",
    "table_24 = ImportData(\"\"\"\n",
    "U;A;P;Y;F;C;B\n",
    "-1;-1;-1;-1;39;1.328;170\n",
    "1;-1;-1;-1;87;1.699;122\n",
    "-1;1;-1;-1;48;1.332;473\n",
    "1;1;-1;-1;71;1.979;511\n",
    "-1;-1;1;-1;43;1.458;156\n",
    "1;-1;1;-1;84;2.189;204\n",
    "-1;1;1;-1;45;1.343;385\n",
    "1;1;1;-1;112;1.707;288\n",
    "-1;-1;-1;1;19;1.257;114\n",
    "1;-1;-1;1;146;2.148;116\n",
    "-1;1;-1;1;50;1.592;244\n",
    "1;1;-1;1;92;1.726;126\n",
    "-1;-1;1;1;107;1.203;72\n",
    "1;-1;1;1;172;2.261;210\n",
    "-1;1;1;1;62;1.434;234\n",
    "1;1;1;1;82;1.848;154\n",
    "0;0;0;0;75;1.726;223\n",
    "0;0;0;0;70;1.782;219\n",
    "0;0;0;0;89;1.753;226\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_24.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table_24.parse_levels(\"\"\";U;A;P;Y\n",
    "#-1;0.15;0.7; 0.40;0.13\n",
    "#0; 0.30;1.4; 0.75;0.26\n",
    "#1; 0.45;2.1; 1.10;0.38\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from explann.models import FactorialModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = FactorialModel(\n",
    "    data=table_24.data, \n",
    "    functions=\n",
    "    {\n",
    "        \"F\" : \"F ~ U * A * P * Y\",\n",
    "        \"C\" : \"C ~ U * A * P * Y\",\n",
    "        \"B\" : \"B ~ U * A * P * Y\"\n",
    "    })\n",
    "\n",
    "print(fm['C'].summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.anova()['B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = {key:val for key,val in fm.functions.items() if key in ['F','C']}\n",
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.anova()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.lack_of_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.get_significant_terms('F')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.get_significant_model_functions('F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_fm = fm.build_significant_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.get_significant_terms('F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_fm.get_significant_terms('F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_fm.lack_of_fit(baseline=fm)['F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_fm['F'].summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_fm.lack_of_fit()['F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_GL = sig_fm['F'].df_model\n",
    "residual_GL = sig_fm.anova()['F'].df['Residual']\n",
    "lof_GL = sig_fm.lack_of_fit()['F']['results']['df_resid'][1]\n",
    "error_GL = sig_fm.lack_of_fit()['F']['results']['df_diff'][1]\n",
    "sum_GL = regression_GL + residual_GL + lof_GL + error_GL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_SQ = sig_fm.anova()['F'].sum_sq.sum() - sig_fm.anova()['F'].sum_sq['Residual']\n",
    "residual_SQ = sig_fm.anova()['F'].sum_sq['Residual']\n",
    "lof_SQ = sig_fm.lack_of_fit()['F']['lack_of_fit']\n",
    "error_SQ = sig_fm.lack_of_fit()['F']['pure_error']\n",
    "\n",
    "regression_MQ = regression_SQ/regression_GL\n",
    "residual_MQ = residual_SQ/residual_GL\n",
    "lof_MQ = lof_SQ/lof_GL\n",
    "error_MQ = error_SQ/error_GL\n",
    "\n",
    "regression_F = regression_MQ/residual_MQ\n",
    "lof_F = lof_MQ/error_MQ\n",
    "regression_F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f\n",
    "\n",
    "tabelado_F = f.ppf(q=1-0.05, dfn=regression_GL, dfd=residual_GL)\n",
    "tabelado_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lof_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabelado_F = f.ppf(q=1-0.05, dfn=lof_GL, dfd=error_GL)\n",
    "tabelado_F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_fm.anova()['F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_fm['F'].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f\n",
    "\n",
    "# tabela F\n",
    "F = f.ppf(q=1-0.05, dfn=9, dfd=4)\n",
    "print(F)\n",
    "pValue = 1.0 - f.cdf(F, 9, 4)\n",
    "print(pValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_fm.lack_of_fit()['F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_sig_fm = sig_fm.anova()['F']\n",
    "#anova_sig_fm.sum_sq.sum()- anova_sig_fm.sum_sq['Residual']\n",
    "regression_GL = sig_fm['F'].df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_fm.lack_of_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.get_significant_terms('F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm.get_significant_model_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_fm = FactorialModel(\n",
    "    data=table_24.data,\n",
    "    functions={'F': 'F ~ U + A + U:A + P + Y + A:Y + U:A:Y + U:P:Y + A:P:Y',\n",
    " 'C': 'C ~ 1 + U + U:A + U:A:Y',\n",
    " 'B': 'B ~ 1 + U + A + U:A + P + U:P + A:P + U:A:P + Y + A:Y + U:A:Y + P:Y + U:P:Y + A:P:Y + U:A:P:Y'}     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.api import anova_lm\n",
    "anova_lm(sig_fm['F'], fm['F'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_fm = FactorialModel(\n",
    "    data=table_24.data,\n",
    "    functions= {\n",
    "        \"F\" : \"F ~ U + A + U:A + P + Y + A:Y + U:A:Y + U:P:Y + A:P:Y\",\n",
    "    }\n",
    ")\n",
    "\n",
    "sig_fm.lack_of_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_24_table_fact = factor_24_table.copy()\n",
    "factor_24_table_fact['U'] = factor_24_table_fact['U'].astype('category')\n",
    "factor_24_table_fact['A'] = factor_24_table_fact['A'].astype('category')\n",
    "factor_24_table_fact['P'] = factor_24_table_fact['P'].astype('category')\n",
    "factor_24_table_fact['Y'] = factor_24_table_fact['Y'].astype('category')\n",
    "lm_fact = ols(formula, factor_24_table_fact).fit()\n",
    "\n",
    "\n",
    "lm_fact = ols(\"FPase ~  C(A)*C(U)*C(P)*C(Y)\", factor_24_table).fit()\n",
    "\n",
    "an = anova_lm(lm, lm_fact)\n",
    "print(an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "an.ss_diff[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "an.ssr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.predict({'U':0, 'A':0, 'P':0, 'Y':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# significant model\n",
    "lm_sig = ols(\"FPase ~ 1 + A + U + A:U + P + Y + A:Y + A:U:Y + A:P:Y + U:P:Y\", factor_24_table).fit()\n",
    "\n",
    "print(lm_sig.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# significant model\n",
    "lm_sig = ols(\"FPase ~ 1 + A + U + A*U + P + Y + A*Y + A*U*Y + A*P*Y + U*P*Y\", factor_24_table).fit()\n",
    "\n",
    "print(lm_sig.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "u, y = np.meshgrid(\n",
    "    np.linspace(factor_24_levels['U']['-1'], factor_24_levels['U']['1'], 10),\n",
    "    np.linspace(factor_24_levels['Y']['-1'], factor_24_levels['Y']['1'], 10),\n",
    "    )\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "\n",
    "\n",
    "ax.plot_surface(u, y, \n",
    "                lm.predict(pd.DataFrame(\n",
    "                    {\n",
    "                        'U': u.ravel(), \n",
    "                        'A': np.ones_like(u.ravel())*factor_24_levels['A']['0'],  \n",
    "                        'Y':y.ravel(),\n",
    "                        'P': np.ones_like(u.ravel())*factor_24_levels['P']['0']\n",
    "                    })).values.reshape(u.shape), cmap='viridis', edgecolor='none')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Central Composite Rotational Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccrm_table = StringIO(\"\"\"\n",
    "U\tY\tFPase\tCMCase\tBglucosidase\n",
    "-1\t-1\t158\t4029\t727\n",
    "-1\t1\t171\t4354\t1119\n",
    "1\t-1\t166\t5302\t1080\n",
    "1\t1\t244\t5513\t1101\n",
    "-1.41\t0\t148\t4481\t743\n",
    "1.41\t0\t263\t6529\t1213\n",
    "0\t-1.41\t208\t5460\t1085\n",
    "0\t1.41\t255\t7105\t1435\n",
    "0\t0\t250\t5364\t1390\n",
    "0\t0\t269\t5524\t1499\n",
    "0\t0\t261\t5793\t1420\n",
    "\"\"\")\n",
    "ccrm_table = pd.read_table(ccrm_table, delimiter='\\t')\n",
    "ccrm_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccrm_levels = StringIO(\"\"\"\n",
    "\t-1.41\t-1\t0\t1\t1.41\n",
    "U\t0.07\t0.4\t1.2\t2\t2.33\n",
    "Y\t0\t0.09\t0.29\t0.5\t0.59\n",
    "\"\"\")\n",
    "\n",
    "ccrm_levels = pd.read_table(ccrm_levels, delimiter='\\s+').T\n",
    "ccrm_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_int = lambda x: int(x) if not x%1 else x\n",
    "\n",
    "def substitute_leveles(table, levels, columns=['U', 'Y']):\n",
    "    for column in columns:\n",
    "        for i,val in enumerate(table[column]):\n",
    "            table[column][i] = levels[column][f\"{to_int(val)}\"]\n",
    "    return table\n",
    "\n",
    "#ccrm_table = substitute_leveles(ccrm_table, ccrm_levels, columns=['U', 'Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccrm_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "#sns.paretoplot(ccrm_table, x='FPase', y='CMCase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = ccrm_table.U\n",
    "Y = ccrm_table.Y\n",
    "FPase = ccrm_table.FPase\n",
    "CMCase = ccrm_table.CMCase\n",
    "Bglucosidase = ccrm_table.Bglucosidase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"FPase ~ 1 + np.power(U,2) + np.power(Y,2) + U + Y\"\n",
    "#formula = \"FPase ~ 1 + U*Y\"\n",
    "lm = ols(formula, ccrm_table).fit(cov_type='HC1')\n",
    "print(lm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.predict(ccrm_table[['U','Y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_lm(lm, type=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "u, y = np.meshgrid(np.linspace(-2, 2, 100), np.linspace(-2, 2, 100))\n",
    "\n",
    "fig, ax = plt.subplots(subplot_kw={\"projection\": \"3d\"})\n",
    "ax.plot_surface(u, y, lm.predict(pd.DataFrame({'U':u.ravel(), 'Y':y.ravel()})).values.reshape(u.shape), cmap='viridis', edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(anova_lm(lm))\n",
    "print(anova_lm(lm, typ=2))\n",
    "print(anova_lm(lm, typ=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "fig = interaction_plot(\n",
    "    x=U.drop([4,5,6,7]),\n",
    "    trace=Y.drop([4,5,6,7]),\n",
    "    response=FPase.drop([4,5,6,7]),\n",
    "    #colors=[\"red\", \"blue\"],\n",
    "    #markers=[\"D\", \"^\"],\n",
    "    #ms=10,\n",
    "    ax=ax,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base code\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from statsmodels.tools.tools import maybe_unwrap_results\n",
    "from statsmodels.graphics.gofplots import ProbPlot\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Type\n",
    "import statsmodels\n",
    "\n",
    "style_talk = 'seaborn-talk'    #refer to plt.style.available\n",
    "\n",
    "class LinearRegDiagnostic():\n",
    "    \"\"\"\n",
    "    Diagnostic plots to identify potential problems in a linear regression fit.\n",
    "    Mainly,\n",
    "        a. non-linearity of data\n",
    "        b. Correlation of error terms\n",
    "        c. non-constant variance\n",
    "        d. outliers\n",
    "        e. high-leverage points\n",
    "        f. collinearity\n",
    "\n",
    "    Authors:\n",
    "        Prajwal Kafle (p33ajkafle@gmail.com, where 3 = r)\n",
    "        Does not come with any sort of warranty.\n",
    "        Please test the code one your end before using.\n",
    "\n",
    "        Matt Spinelli (m3spinelli@gmail.com, where 3 = r)\n",
    "        (1) Fixed incorrect annotation of the top most extreme residuals in\n",
    "            the Residuals vs Fitted and, especially, the Normal Q-Q plots.\n",
    "        (2) Changed Residuals vs Leverage plot to match closer the y-axis\n",
    "            range shown in the equivalent plot in the R package ggfortify.\n",
    "        (3) Added horizontal line at y=0 in Residuals vs Leverage plot to\n",
    "            match the plots in R package ggfortify and base R.\n",
    "        (4) Added option for placing a vertical guideline on the Residuals\n",
    "            vs Leverage plot using the rule of thumb of h = 2p/n to denote\n",
    "            high leverage (high_leverage_threshold=True).\n",
    "        (5) Added two more ways to compute the Cook's Distance (D) threshold:\n",
    "            * 'baseR': D > 1 and D > 0.5 (default)\n",
    "            * 'convention': D > 4/n\n",
    "            * 'dof': D > 4 / (n - k - 1)\n",
    "        (6) Fixed class name to conform to Pascal casing convention\n",
    "        (7) Fixed Residuals vs Leverage legend to work with loc='best'\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 results: Type[statsmodels.regression.linear_model.RegressionResultsWrapper]) -> None:\n",
    "        \"\"\"\n",
    "        For a linear regression model, generates following diagnostic plots:\n",
    "\n",
    "        a. residual\n",
    "        b. qq\n",
    "        c. scale location and\n",
    "        d. leverage\n",
    "\n",
    "        and a table\n",
    "\n",
    "        e. vif\n",
    "\n",
    "        Args:\n",
    "            results (Type[statsmodels.regression.linear_model.RegressionResultsWrapper]):\n",
    "                must be instance of statsmodels.regression.linear_model object\n",
    "\n",
    "        Raises:\n",
    "            TypeError: if instance does not belong to above object\n",
    "\n",
    "        Example:\n",
    "        >>> import numpy as np\n",
    "        >>> import pandas as pd\n",
    "        >>> import statsmodels.formula.api as smf\n",
    "        >>> x = np.linspace(-np.pi, np.pi, 100)\n",
    "        >>> y = 3*x + 8 + np.random.normal(0,1, 100)\n",
    "        >>> df = pd.DataFrame({'x':x, 'y':y})\n",
    "        >>> res = smf.ols(formula= \"y ~ x\", data=df).fit()\n",
    "        >>> cls = Linear_Reg_Diagnostic(res)\n",
    "        >>> cls(plot_context=\"seaborn-paper\")\n",
    "\n",
    "        In case you do not need all plots you can also independently make an individual plot/table\n",
    "        in following ways\n",
    "\n",
    "        >>> cls = Linear_Reg_Diagnostic(res)\n",
    "        >>> cls.residual_plot()\n",
    "        >>> cls.qq_plot()\n",
    "        >>> cls.scale_location_plot()\n",
    "        >>> cls.leverage_plot()\n",
    "        >>> cls.vif_table()\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(results, statsmodels.regression.linear_model.RegressionResultsWrapper) is False:\n",
    "            raise TypeError(\"result must be instance of statsmodels.regression.linear_model.RegressionResultsWrapper object\")\n",
    "\n",
    "        self.results = maybe_unwrap_results(results)\n",
    "\n",
    "        self.y_true = self.results.model.endog\n",
    "        self.y_predict = self.results.fittedvalues\n",
    "        self.xvar = self.results.model.exog\n",
    "        self.xvar_names = self.results.model.exog_names\n",
    "\n",
    "        self.residual = np.array(self.results.resid)\n",
    "        influence = self.results.get_influence()\n",
    "        self.residual_norm = influence.resid_studentized_internal\n",
    "        self.leverage = influence.hat_matrix_diag\n",
    "        self.cooks_distance = influence.cooks_distance[0]\n",
    "        self.nparams = len(self.results.params)\n",
    "        self.nresids = len(self.residual_norm)\n",
    "\n",
    "    def __call__(self, plot_context='seaborn-paper', **kwargs):\n",
    "        # print(plt.style.available)\n",
    "        with plt.style.context(plot_context):\n",
    "            fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(10,10))\n",
    "            self.residual_plot(ax=ax[0,0])\n",
    "            self.qq_plot(ax=ax[0,1])\n",
    "            self.scale_location_plot(ax=ax[1,0])\n",
    "            self.leverage_plot(\n",
    "                ax=ax[1,1],\n",
    "                high_leverage_threshold = kwargs.get('high_leverage_threshold'),\n",
    "                cooks_threshold = kwargs.get('cooks_threshold'))\n",
    "            plt.show()\n",
    "\n",
    "        return self.vif_table(), fig, ax,\n",
    "\n",
    "    def residual_plot(self, ax=None):\n",
    "        \"\"\"\n",
    "        Residual vs Fitted Plot\n",
    "\n",
    "        Graphical tool to identify non-linearity.\n",
    "        (Roughly) Horizontal red line is an indicator that the residual has a linear pattern\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        sns.residplot(\n",
    "            x=self.y_predict,\n",
    "            y=self.residual,\n",
    "            lowess=True,\n",
    "            scatter_kws={'alpha': 0.5},\n",
    "            line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8},\n",
    "            ax=ax)\n",
    "\n",
    "        # annotations\n",
    "        residual_abs = np.abs(self.residual)\n",
    "        abs_resid = np.flip(np.argsort(residual_abs), 0)\n",
    "        abs_resid_top_3 = abs_resid[:3]\n",
    "        for i in abs_resid_top_3:\n",
    "            ax.annotate(\n",
    "                i,\n",
    "                xy=(self.y_predict[i], self.residual[i]),\n",
    "                color='C3')\n",
    "\n",
    "        ax.set_title('Residuals vs Fitted', fontweight=\"bold\")\n",
    "        ax.set_xlabel('Fitted values')\n",
    "        ax.set_ylabel('Residuals')\n",
    "        return ax\n",
    "\n",
    "    def qq_plot(self, ax=None):\n",
    "        \"\"\"\n",
    "        Standarized Residual vs Theoretical Quantile plot\n",
    "\n",
    "        Used to visually check if residuals are normally distributed.\n",
    "        Points spread along the diagonal line will suggest so.\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        QQ = ProbPlot(self.residual_norm)\n",
    "        fig = QQ.qqplot(line='45', alpha=0.5, lw=1, ax=ax)\n",
    "\n",
    "        # annotations\n",
    "        abs_norm_resid = np.flip(np.argsort(np.abs(self.residual_norm)), 0)\n",
    "        abs_norm_resid_top_3 = abs_norm_resid[:3]\n",
    "        for i, x, y in self.__qq_top_resid(QQ.theoretical_quantiles, abs_norm_resid_top_3):\n",
    "            ax.annotate(\n",
    "                i,\n",
    "                xy=(x, y),\n",
    "                ha='right',\n",
    "                color='C3')\n",
    "\n",
    "        ax.set_title('Normal Q-Q', fontweight=\"bold\")\n",
    "        ax.set_xlabel('Theoretical Quantiles')\n",
    "        ax.set_ylabel('Standardized Residuals')\n",
    "        return ax\n",
    "\n",
    "    def scale_location_plot(self, ax=None):\n",
    "        \"\"\"\n",
    "        Sqrt(Standarized Residual) vs Fitted values plot\n",
    "\n",
    "        Used to check homoscedasticity of the residuals.\n",
    "        Horizontal line will suggest so.\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        residual_norm_abs_sqrt = np.sqrt(np.abs(self.residual_norm))\n",
    "\n",
    "        ax.scatter(self.y_predict, residual_norm_abs_sqrt, alpha=0.5);\n",
    "        sns.regplot(\n",
    "            x=self.y_predict,\n",
    "            y=residual_norm_abs_sqrt,\n",
    "            scatter=False, ci=False,\n",
    "            lowess=True,\n",
    "            line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8},\n",
    "            ax=ax)\n",
    "\n",
    "        # annotations\n",
    "        abs_sq_norm_resid = np.flip(np.argsort(residual_norm_abs_sqrt), 0)\n",
    "        abs_sq_norm_resid_top_3 = abs_sq_norm_resid[:3]\n",
    "        for i in abs_sq_norm_resid_top_3:\n",
    "            ax.annotate(\n",
    "                i,\n",
    "                xy=(self.y_predict[i], residual_norm_abs_sqrt[i]),\n",
    "                color='C3')\n",
    "\n",
    "        ax.set_title('Scale-Location', fontweight=\"bold\")\n",
    "        ax.set_xlabel('Fitted values')\n",
    "        ax.set_ylabel(r'$\\sqrt{|\\mathrm{Standardized\\ Residuals}|}$');\n",
    "        return ax\n",
    "\n",
    "    def leverage_plot(self, ax=None, high_leverage_threshold=False, cooks_threshold='baseR'):\n",
    "        \"\"\"\n",
    "        Residual vs Leverage plot\n",
    "\n",
    "        Points falling outside Cook's distance curves are considered observation that can sway the fit\n",
    "        aka are influential.\n",
    "        Good to have none outside the curves.\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        ax.scatter(\n",
    "            self.leverage,\n",
    "            self.residual_norm,\n",
    "            alpha=0.5);\n",
    "\n",
    "        sns.regplot(\n",
    "            x=self.leverage,\n",
    "            y=self.residual_norm,\n",
    "            scatter=False,\n",
    "            ci=False,\n",
    "            lowess=True,\n",
    "            line_kws={'color': 'red', 'lw': 1, 'alpha': 0.8},\n",
    "            ax=ax)\n",
    "\n",
    "        # annotations\n",
    "        leverage_top_3 = np.flip(np.argsort(self.cooks_distance), 0)[:3]\n",
    "        for i in leverage_top_3:\n",
    "            ax.annotate(\n",
    "                i,\n",
    "                xy=(self.leverage[i], self.residual_norm[i]),\n",
    "                color = 'C3')\n",
    "\n",
    "        factors = []\n",
    "        if cooks_threshold == 'baseR' or cooks_threshold is None:\n",
    "            factors = [1, 0.5]\n",
    "        elif cooks_threshold == 'convention':\n",
    "            factors = [4/self.nresids]\n",
    "        elif cooks_threshold == 'dof':\n",
    "            factors = [4/ (self.nresids - self.nparams)]\n",
    "        else:\n",
    "            raise ValueError(\"threshold_method must be one of the following: 'convention', 'dof', or 'baseR' (default)\")\n",
    "        for i, factor in enumerate(factors):\n",
    "            label = \"Cook's distance\" if i == 0 else None\n",
    "            xtemp, ytemp = self.__cooks_dist_line(factor)\n",
    "            ax.plot(xtemp, ytemp, label=label, lw=1.25, ls='--', color='red')\n",
    "            ax.plot(xtemp, np.negative(ytemp), lw=1.25, ls='--', color='red')\n",
    "\n",
    "        if high_leverage_threshold:\n",
    "            high_leverage = 2 * self.nparams / self.nresids\n",
    "            if max(self.leverage) > high_leverage:\n",
    "                ax.axvline(high_leverage, label='High leverage', ls='-.', color='purple', lw=1)\n",
    "\n",
    "        ax.axhline(0, ls='dotted', color='black', lw=1.25)\n",
    "        ax.set_xlim(0, max(self.leverage)+0.01)\n",
    "        ax.set_ylim(min(self.residual_norm)-0.1, max(self.residual_norm)+0.1)\n",
    "        ax.set_title('Residuals vs Leverage', fontweight=\"bold\")\n",
    "        ax.set_xlabel('Leverage')\n",
    "        ax.set_ylabel('Standardized Residuals')\n",
    "        plt.legend(loc='best')\n",
    "        return ax\n",
    "\n",
    "    def vif_table(self):\n",
    "        \"\"\"\n",
    "        VIF table\n",
    "\n",
    "        VIF, the variance inflation factor, is a measure of multicollinearity.\n",
    "        VIF > 5 for a variable indicates that it is highly collinear with the\n",
    "        other input variables.\n",
    "        \"\"\"\n",
    "        vif_df = pd.DataFrame()\n",
    "        vif_df[\"Features\"] = self.xvar_names\n",
    "        vif_df[\"VIF Factor\"] = [variance_inflation_factor(self.xvar, i) for i in range(self.xvar.shape[1])]\n",
    "\n",
    "        return (vif_df\n",
    "                .sort_values(\"VIF Factor\")\n",
    "                .round(2))\n",
    "\n",
    "\n",
    "    def __cooks_dist_line(self, factor):\n",
    "        \"\"\"\n",
    "        Helper function for plotting Cook's distance curves\n",
    "        \"\"\"\n",
    "        p = self.nparams\n",
    "        formula = lambda x: np.sqrt((factor * p * (1 - x)) / x)\n",
    "        x = np.linspace(0.001, max(self.leverage), 50)\n",
    "        y = formula(x)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "    def __qq_top_resid(self, quantiles, top_residual_indices):\n",
    "        \"\"\"\n",
    "        Helper generator function yielding the index and coordinates\n",
    "        \"\"\"\n",
    "        offset = 0\n",
    "        quant_index = 0\n",
    "        previous_is_negative = None\n",
    "        for resid_index in top_residual_indices:\n",
    "            y = self.residual_norm[resid_index]\n",
    "            is_negative = y < 0\n",
    "            if previous_is_negative == None or previous_is_negative == is_negative:\n",
    "                offset += 1\n",
    "            else:\n",
    "                quant_index -= offset\n",
    "            x = quantiles[quant_index] if is_negative else np.flip(quantiles, 0)[quant_index]\n",
    "            quant_index += 1\n",
    "            previous_is_negative = is_negative\n",
    "            yield resid_index, x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = LinearRegDiagnostic(lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls.scale_location_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls.leverage_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls.leverage_plot(high_leverage_threshold=True, cooks_threshold='dof')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=True, interaction_only=True)\n",
    "X = poly.fit_transform(ccrm_table[['U','Y']])\n",
    "y = ccrm_table['FPase']\n",
    "poly.fit(X, y)\n",
    "\n",
    "lin = LinearRegression(fit_intercept=False)\n",
    "lin.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = LinearRegDiagnostic(lm)\n",
    "vif, fig, ax = cls()\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "fig = sm.graphics.influence_plot(lm, criterion=\"cooks\")\n",
    "fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sm.graphics.plot_partregress_grid(lm)\n",
    "fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sm.graphics.plot_regress_exog(lm, \"U\")\n",
    "fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sm.graphics.plot_fit(lm, \"U\")\n",
    "fig.tight_layout(pad=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "md = smf.mixedlm(formula, ccrm_table, groups=ccrm_table['U']\n",
    ")\n",
    "mdf = md.fit(method=[\"lbfgs\"])\n",
    "print(mdf.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ppiper/Dropbox/local/github/explann')\n",
    "\n",
    "from explann.dataio import ImportData\n",
    "from explann.models import FactorialModel\n",
    "\n",
    "example_data = ImportData(\n",
    "\"\"\"\n",
    "Fe loss\n",
    "1 0.01 127.6\n",
    "2 0.48 124.0\n",
    "3 0.71 110.8\n",
    "4 0.95 103.9\n",
    "5 1.19 101.5\n",
    "6 0.01 130.1\n",
    "7 0.48 122.0\n",
    "8 1.44 92.3\n",
    "9 0.71 113.1\n",
    "10 1.96 83.7\n",
    "11 0.01 128.0\n",
    "12 1.44 91.4\n",
    "13 1.96 86.2\n",
    "\"\"\"\n",
    ", delimiter=' ', index_col=0)\n",
    "\n",
    "example_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_model  = FactorialModel(\n",
    "    data=example_data.data, \n",
    "    functions=\n",
    "    {\n",
    "        \"loss\" : \"loss ~ Fe\",\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_model.lack_of_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
